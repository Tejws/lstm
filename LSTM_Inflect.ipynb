{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_qwDij45D7R",
        "outputId": "bb3e7d63-1ee2-4f3a-e4bb-bb3e0b123f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 35.6792\n",
            "Generated sentence with LSTM output and Inflect conversion:\n",
            "one two three four five\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import inflect\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Initialize the Inflect engine\n",
        "p = inflect.engine()\n",
        "\n",
        "# Define a simple LSTM model for sequence generation (just for demonstration)\n",
        "model = Sequential([\n",
        "    LSTM(50, input_shape=(5, 1), return_sequences=True),  # LSTM with input shape (5, 1)\n",
        "    LSTM(50),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Dummy data for LSTM (let's assume we are training the model on sequence of numbers)\n",
        "data = np.array([1, 2, 3, 4, 5])  # Sample data (numbers)\n",
        "data = data.reshape((1, 5, 1))  # Reshape data for LSTM input\n",
        "\n",
        "# Fit model (This is just an example, and we won't actually train it for now)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(data, np.array([6]), epochs=1)  # Predicting the next number in the sequence\n",
        "\n",
        "# Generate a number sequence using LSTM (let's assume this is the output of the LSTM)\n",
        "lstm_output = np.array([1, 2, 3, 4, 5])  # Generated sequence from LSTM model\n",
        "\n",
        "# Convert the numbers in the sequence to words using Inflect\n",
        "lstm_output_words = [p.number_to_words(num) for num in lstm_output]\n",
        "\n",
        "# Join the sequence into a sentence\n",
        "sentence = \" \".join(lstm_output_words)\n",
        "print(\"Generated sentence with LSTM output and Inflect conversion:\")\n",
        "print(sentence)\n"
      ]
    }
  ]
}